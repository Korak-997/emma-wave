import logging
from fastapi import FastAPI, File, UploadFile
from fastapi.middleware.cors import CORSMiddleware
from pyannote.audio import Pipeline
from app.utils.audio_utils import (
    convert_audio_format,
    validate_audio_format,
    merge_speaker_segments,
    extract_speaker_segments
)
from app.utils.config import get_huggingface_token
from app.utils.exceptions import InvalidAudioFormatError, AudioProcessingError, ModelLoadingError
import io

# ‚úÖ Configure Logging
logging.basicConfig(
    level=logging.INFO,
    format="%(asctime)s - %(levelname)s - %(message)s",
    handlers=[logging.StreamHandler()],
)

# ‚úÖ Load Hugging Face Token
HUGGINGFACE_TOKEN = get_huggingface_token()

# ‚úÖ Initialize FastAPI app
app = FastAPI()

# ‚úÖ Fix CORS issues for frontend requests
app.add_middleware(
    CORSMiddleware,
    allow_origins=["*"],  # Change to specific domains later for security
    allow_credentials=True,
    allow_methods=["*"],
    allow_headers=["*"],
)

# ‚úÖ Load the diarization pipeline
try:
    logging.info("‚è≥ Loading Pyannote Speaker Diarization Model...")
    pipeline = Pipeline.from_pretrained("pyannote/speaker-diarization", use_auth_token=HUGGINGFACE_TOKEN)
    logging.info("‚úÖ Pyannote model loaded successfully!")
except Exception as e:
    logging.error(f"üö® Failed to load Pyannote model: {e}")
    raise ModelLoadingError()

@app.post("/diarize")
async def diarize_audio(file: UploadFile = File(...)):
    """
    Process an uploaded audio file, segment it by speakers, and return results.
    """
    logging.info(f"üì• Received file: {file.filename}")

    # ‚úÖ Read file into memory
    original_audio = await file.read()

    try:
        # ‚úÖ Validate format before processing
        if not validate_audio_format(original_audio):
            original_audio = convert_audio_format(original_audio)  # Convert in-memory

        # ‚úÖ Process the file using Pyannote
        logging.info("üîÑ Processing audio for diarization...")
        diarization_result = pipeline(io.BytesIO(original_audio))
        logging.info("‚úÖ Speaker diarization completed!")

        # ‚úÖ Extract speaker segments
        raw_segments = [
            {"speaker": speaker, "start": round(segment.start, 2), "end": round(segment.end, 2)}
            for segment, _, speaker in diarization_result.itertracks(yield_label=True)
        ]

        # ‚úÖ Merge speaker segments to remove small gaps
        merged_segments = merge_speaker_segments(raw_segments)

        # ‚úÖ Extract speaker-specific audio clips
        speaker_audio_segments = extract_speaker_segments(original_audio, merged_segments)

        logging.info(f"üìä Processed {len(merged_segments)} merged segments from {file.filename}")

    except InvalidAudioFormatError as e:
        raise e
    except AudioProcessingError as e:
        raise e
    except Exception as e:
        logging.error(f"üö® Error processing audio: {e}")
        raise AudioProcessingError("Unexpected error occurred during processing.")

    # ‚úÖ Return structured response with original audio & segments
    return {
        "file": file.filename,
        "original_audio": original_audio,
        "speakers": speaker_audio_segments
    }

@app.get("/health")
async def health_check():
    """
    Health check endpoint to ensure API and diarization model are running correctly.
    """
    try:
        # ‚úÖ Check if the diarization model is loaded
        if not pipeline:
            raise RuntimeError("Diarization model is not loaded.")

        return {"status": "ok", "model": "loaded"}

    except Exception as e:
        logging.error(f"üö® Health check failed: {e}")
        return {"status": "error", "message": str(e)}
